{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import fiona\n",
    "import rasterio\n",
    "import rasterio.mask\n",
    "from rasterio.windows import Window\n",
    "\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/semester_project/lib/python3.11/site-packages/shapely/predicates.py:853: RuntimeWarning: invalid value encountered in overlaps\n",
      "  return lib.overlaps(a, b, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# load all CAR\n",
    "path = \"../data/car/acre/\"\n",
    "folders = [name for name in os.listdir(path) if \"SHAPE\" in name]\n",
    "df = gpd.GeoDataFrame()\n",
    "for folder in folders:\n",
    "    df_new = gpd.read_file(path + folder + \"/AREA_IMOVEL/AREA_IMOVEL.shp\")\n",
    "    df = pd.concat([df, df_new])\n",
    "\n",
    "# load sample project area\n",
    "gpd.io.file.fiona.drvsupport.supported_drivers['KML'] = 'rw'\n",
    "path_pa = \"../data/pa/ValparaisoProperty (Kml).kml\"\n",
    "pa = gpd.read_file(path_pa, driver='KML')\n",
    "pa = pa.to_crs(\"EPSG:4674\")\n",
    "\n",
    "# function to load biomass data\n",
    "def load_biomass_data(year, shape, resolution=250):\n",
    "    path_bio = f\"../data/biomass/{resolution}m/\" + f\"mapbiomas-brazil-collection-70-acre-{year}.tif\"\n",
    "    with rasterio.open(path_bio) as src:\n",
    "        if shape is not None:\n",
    "            bio_data, out_transform = rasterio.mask.mask(src, shape, crop=True)\n",
    "        else:\n",
    "            bio_data = src.read(1)\n",
    "        bio_data = np.squeeze(bio_data)\n",
    "        out_meta = src.meta\n",
    "    return bio_data\n",
    "\n",
    "# function to transform labels to 1=forest, 2=non_forest, 0=unknown\n",
    "def transform_to_labels(bio_data):\n",
    "    class_dict = {1:1, 3:1, 4:1, 5:1,49:1, # forest\n",
    "                10:2,11:2,12:2,32:2,29:2,13:2, 13:2, 50:2, # natural\n",
    "                14:2,15:2,18:2,19:2,39:2,20:2,40:2,61:2,41:2,36:2,46:2,47:2,48:2,9:2,21:2, # farming\n",
    "                22:2,23:2,24:2,30:2,25:2, # urban\n",
    "                26:2,33:2,31:2, # water\n",
    "                27:0,0:0} # unobserved\n",
    "    bio_data_new = np.zeros_like(bio_data)\n",
    "    for key, value in class_dict.items():\n",
    "        bio_data_new[bio_data == key] = value\n",
    "    return np.array(bio_data_new, dtype=np.int8)\n",
    "\n",
    "# calculate CAR area\n",
    "df['area_6933'] = df.geometry.to_crs(\"EPSG:6933\").area\n",
    "\n",
    "# filter by area\n",
    "pa_area = pa.to_crs(\"EPSG:6933\").area.sum()\n",
    "df = df[(df.area_6933 > 0.75 * pa_area) & (df.area_6933 < 1.25 * pa_area)]\n",
    "\n",
    "# avoid overlap\n",
    "for polygon in pa.geometry:\n",
    "    df = df[np.invert(df.overlaps(polygon).values)]\n",
    "\n",
    "# ensure sufficient forest cover\n",
    "forest_cover_1985 = []\n",
    "for car in df.iterrows():\n",
    "    bio_data = load_biomass_data(1985, [car[1].geometry], resolution=250)\n",
    "    bio_data = transform_to_labels(bio_data)\n",
    "    forest_cover = np.count_nonzero(bio_data == 1) / np.count_nonzero(bio_data > 0)\n",
    "    forest_cover_1985.append(forest_cover)\n",
    "df['fc_1985'] = forest_cover_1985\n",
    "df = df[df.fc_1985 >= 0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "37it [00:04,  7.91it/s]\n"
     ]
    }
   ],
   "source": [
    "# load car images as tensors\n",
    "car_tensors = []\n",
    "\n",
    "start_train = 2006\n",
    "start_target = 2016\n",
    "start_test = 2019\n",
    "horizon = 3\n",
    "\n",
    "patch_size = 400\n",
    "overlap = 100\n",
    "\n",
    "for car in tqdm(df.iterrows()):\n",
    "    years = np.arange(start_train, start_test+horizon)\n",
    "\n",
    "    bio_data_dict = {}\n",
    "    for year in years:\n",
    "        bio_data = load_biomass_data(year, [car[1].geometry], resolution=30)\n",
    "        bio_data = transform_to_labels(bio_data)\n",
    "        bio_data_dict[year] = bio_data\n",
    "\n",
    "    deforestation = np.zeros_like(bio_data_dict[start_target - 1], dtype=bool)\n",
    "    for year in np.arange(start_target, start_target+horizon):\n",
    "        deforested = bio_data_dict[start_target - 1] - bio_data_dict[year]\n",
    "        deforestation = deforestation | (deforested < 0)\n",
    "    bio_data_dict[1111] = deforestation\n",
    "    \n",
    "    car_tensors.append(np.array(list(bio_data_dict.values())))\n",
    "shapes = [car_tensor.shape for car_tensor in car_tensors]\n",
    "target_shape = np.max(shapes, axis=0)\n",
    "residual = np.array([target_shape[0], patch_size, patch_size]) - target_shape%patch_size\n",
    "target_shape = target_shape + residual\n",
    "reshaped_car_tensors = []\n",
    "for car_tensor in car_tensors:\n",
    "    reshaped_car_tensors.append(np.pad(car_tensor, (\n",
    "        (0, 0), \n",
    "        (0, target_shape[1] - car_tensor.shape[1]), \n",
    "        (0, target_shape[2] - car_tensor.shape[2]))\n",
    "    ))\n",
    "reshaped_car_tensors = np.array(reshaped_car_tensors)\n",
    "\n",
    "# to torch and split in patches\n",
    "car_tensors = torch.from_numpy(reshaped_car_tensors)\n",
    "patches = car_tensors.unfold(2, patch_size, patch_size - overlap)\n",
    "patches = patches.unfold(3, patch_size, patch_size - overlap)\n",
    "patches = torch.moveaxis(patches, 1, -1)\n",
    "patches = torch.flatten(patches, 0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([344, 400, 400, 17])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patches[patches[:,:,:,0].sum(axis=1).sum(axis=1) > 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([258, 400, 400, 17])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patches[patches[:,:,:,-1].sum(axis=1).sum(axis=1) > 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load entire image\n",
    "\n",
    "start_train = 2006\n",
    "start_target = 2016\n",
    "start_test = 2019\n",
    "horizon = 3\n",
    "\n",
    "patch_size = 400\n",
    "overlap = 0\n",
    "\n",
    "years = np.arange(start_train, start_test+horizon)\n",
    "\n",
    "bio_data_dict = {}\n",
    "for year in years:\n",
    "    bio_data = load_biomass_data(year, None, resolution=30)\n",
    "    bio_data = transform_to_labels(bio_data)\n",
    "    bio_data_dict[year] = bio_data\n",
    "\n",
    "deforestation = np.zeros_like(bio_data_dict[start_target - 1], dtype=bool)\n",
    "for year in np.arange(start_target, start_target+horizon):\n",
    "    deforested = bio_data_dict[start_target - 1] - bio_data_dict[year]\n",
    "    deforestation = deforestation | (deforested < 0)\n",
    "bio_data_dict[1111] = deforestation\n",
    "\n",
    "site_tensor = np.array(list(bio_data_dict.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_shape = np.array(site_tensor.shape)\n",
    "residual = np.array([target_shape[0], patch_size, patch_size]) - target_shape%patch_size\n",
    "target_shape = target_shape + residual\n",
    "reshaped_site_tensor = np.pad(site_tensor, (\n",
    "        (0, 0), \n",
    "        (0, target_shape[1] - site_tensor.shape[1]), \n",
    "        (0, target_shape[2] - site_tensor.shape[2]))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to torch and split in patches\n",
    "site_tensor = torch.from_numpy(reshaped_site_tensor)\n",
    "patches = site_tensor.unfold(1, patch_size, patch_size - overlap)\n",
    "patches = patches.unfold(2, patch_size, patch_size - overlap)\n",
    "patches = torch.moveaxis(patches, 0, -1)\n",
    "patches = torch.flatten(patches, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non empty patch:  torch.Size([1277, 400, 400, 17])\n",
      "Changing patch:  torch.Size([1091, 400, 400, 17])\n"
     ]
    }
   ],
   "source": [
    "print('Non empty patch: ', patches[patches[:,:,:,0].sum(axis=1).sum(axis=1) > 0].shape)\n",
    "print('Changing patch: ', patches[patches[:,:,:,-1].sum(axis=1).sum(axis=1) > 0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "patches = patches[patches[:,:,:,-1].sum(axis=1).sum(axis=1) > 0]\n",
    "patches = patches[:,:,:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into train and test sets\n",
    "nr_years_train = start_target - start_train\n",
    "train_patches, val_patches, train_labels, val_labels = train_test_split(patches[:,:,:,:nr_years_train], patches[:,:,:,nr_years_train:nr_years_train+horizon], test_size=0.2, random_state=42)\n",
    "test_patches = patches[:,:,:,horizon:nr_years_train+horizon]\n",
    "test_labels = patches[:,:,:,-horizon:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the train and test datasets using the train_patches and test_patches tensors\n",
    "train_dataset = torch.utils.data.TensorDataset(train_patches, train_labels)\n",
    "val_dataset = torch.utils.data.TensorDataset(val_patches, val_labels)\n",
    "test_dataset = torch.utils.data.TensorDataset(test_patches, test_labels)\n",
    "\n",
    "# create the data loaders for the train and test datasets\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "semester_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
